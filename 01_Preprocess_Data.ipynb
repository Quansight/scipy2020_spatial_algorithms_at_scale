{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import geopandas as gpd\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from shapely.geometry import Polygon, box\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from distributed import LocalCluster, Client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download zip code shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create title and url for zip code data\n",
    "title = 'US Census Data - Zip Code Boundaries'\n",
    "url = 'https://www2.census.gov/geo/tiger/TIGER2019/ZCTA5/tl_2019_us_zcta510.zip'\n",
    "\n",
    "# construct an output directory for the data\n",
    "zip_dir = Path(url).stem\n",
    "\n",
    "print(f\"Downloading {title} \\n    From: {url}\\n    To: {zip_dir}\")\n",
    "\n",
    "# get the remote data\n",
    "r = requests.get(url)\n",
    "# convert to zipfile format\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "# extract the zip contents\n",
    "z.extractall(zip_dir)\n",
    "\n",
    "# construct path to the shapefile\n",
    "shapefile = f\"{zip_dir}/{zip_dir}.shp\"\n",
    "# load the shapefile into geopandas\n",
    "zips_all = gpd.read_file(shapefile, driver=\"shapefile\").to_crs('epsg:4326')\n",
    "# view the head\n",
    "zips_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter zipcodes to continguous US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bounding box for continuous US\n",
    "contiguous_us_bounding_box = box(-124.848974, 24.396308, -66.885444, 49.384358)\n",
    "# create geodataframe with contiguous bounding box\n",
    "contiguous_us_bbox_gdf = gpd.GeoDataFrame(geometry=[contiguous_us_bounding_box], crs='epsg:4326')\n",
    "\n",
    "# quick and dirty filter of multipolygons (spatialpandas can't handle them yet)\n",
    "# gpdf.geometry = gpdf.geometry.apply(lambda x: x if type(x) == shapely.geometry.Polygon else x[0])\n",
    "zips_subset = zips_all[zips_all.geometry.apply(lambda x: True if type(x)==Polygon else False)]\n",
    "\n",
    "# extract only the zip code number and geometry columns\n",
    "zips_subset = zips_subset[['ZCTA5CE10','geometry']].copy(deep=True)\n",
    "\n",
    "# Filter out Zip Codes outside of Contiguous US\n",
    "zips_subset = gpd.sjoin(zips_subset, contiguous_us_bbox_gdf, op='within')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subsampled zip code datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_sizes = [1, 10, 100, 1000, 10000, len(zips_subset)]\n",
    "# Save various size subsets of the zip code data\n",
    "for sample_size in subsample_sizes:\n",
    "    zips_subset.sample(sample_size, random_state=42).to_file(data_dir.joinpath(f'zips_{sample_size}.geojson'),\n",
    "                                                             driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download OpenStreetMap point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the openstreetmap data\n",
    "# todo replace this with either a download of raw data and/or processing to parquet\n",
    "raw_path = '/work/spd-scipy2020/data/simple-gps-points.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the contiguous US and save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "t0 = time.time()\n",
    "# read the osm raw data\n",
    "ddf = dd.read_parquet(raw_path)\n",
    "# reduce osm data to continguous us\n",
    "usdf = ddf[ddf.latitude.between(24.396308, 49.384358) & ddf.longitude.between(-124.848974, -66.885444)]\n",
    "# write intermediate file\n",
    "usdf.to_parquet('data/contiguous_us.parquet', engine='pyarrow', compression='snappy')\n",
    "dt_hr = (time.time() - t0)/60/60 # 6min 25s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
